{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet sample\n",
    "from https://github.com/HyunLee103/Pytorch_practice/tree/master/UNet_regressionhttps://github.com/HyunLee103/Pytorch_practice/tree/master/UNet_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8aa8bf07c4bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m## 데이터 로더를 구현하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "\n",
    "## 데이터 로더를 구현하기\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None, task=None, opts=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.task = task\n",
    "        self.opts = opts\n",
    "\n",
    "        # Updated at Apr 5 2020\n",
    "        self.to_tensor = ToTensor()\n",
    "\n",
    "        lst_data = os.listdir(self.data_dir)\n",
    "        lst_data = [f for f in lst_data if f.endswith('jpg') | f.endswith('jpeg') | f.endswith('png')]\n",
    "\n",
    "        # lst_label = [f for f in lst_data if f.startswith('label')]\n",
    "        # lst_input = [f for f in lst_data if f.startswith('input')]\n",
    "        #\n",
    "        # lst_label.sort()\n",
    "        # lst_input.sort()\n",
    "        #\n",
    "        # self.lst_label = lst_label\n",
    "        # self.lst_input = lst_input\n",
    "\n",
    "        lst_data.sort()\n",
    "        self.lst_data = lst_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lst_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # label = np.load(os.path.join(self.data_dir, self.lst_label[index]))\n",
    "        # input = np.load(os.path.join(self.data_dir, self.lst_input[index]))\n",
    "\n",
    "        img = plt.imread(os.path.join(self.data_dir, self.lst_data[index]))\n",
    "        sz = img.shape\n",
    "\n",
    "        if sz[0] > sz[1]:\n",
    "            img = img.transpose((1, 0, 2))\n",
    "\n",
    "        if img.ndim == 2:\n",
    "            img = img[:, :, np.newaxis]\n",
    "\n",
    "        if img.dtype == np.uint8:\n",
    "            img = img / 255.0\n",
    "\n",
    "        # label = img\n",
    "        #\n",
    "        # if self.task == \"inpainting\":\n",
    "        #     input = add_sampling(img, type=self.opts[0], opts=self.opts[1])\n",
    "        # elif self.task == \"denoising\":\n",
    "        #     input = add_noise(img, type=self.opts[0], opts=self.opts[1])\n",
    "        # elif self.task == \"super_resolution\":\n",
    "        #     input = add_blur(img, type=self.opts[0], opts=self.opts[1])\n",
    "        #\n",
    "        # data = {'input': input, 'label': label}\n",
    "        #\n",
    "        # if self.transform:\n",
    "        #     data = self.transform(data)\n",
    "\n",
    "        # Updated at Apr 5 2020\n",
    "        data = {'label': img}\n",
    "\n",
    "        if self.task == \"inpainting\":\n",
    "            data['input'] = add_sampling(data['label'], type=self.opts[0], opts=self.opts[1])\n",
    "        elif self.task == \"denoising\":\n",
    "            data['input'] = add_noise(data['label'], type=self.opts[0], opts=self.opts[1])\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        if self.task == \"super_resolution\":\n",
    "            data['input'] = add_blur(data['label'], type=self.opts[0], opts=self.opts[1])\n",
    "\n",
    "        data = self.to_tensor(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "## 트렌스폼 구현하기\n",
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "        # label, input = data['label'], data['input']\n",
    "        #\n",
    "        # label = label.transpose((2, 0, 1)).astype(np.float32)\n",
    "        # input = input.transpose((2, 0, 1)).astype(np.float32)\n",
    "        #\n",
    "        # data = {'label': torch.from_numpy(label), 'input': torch.from_numpy(input)}\n",
    "\n",
    "        # Updated at Apr 5 2020\n",
    "        for key, value in data.items():\n",
    "            value = value.transpose((2, 0, 1)).astype(np.float32)\n",
    "            data[key] = torch.from_numpy(value)\n",
    "\n",
    "        return data\n",
    "\n",
    "class Normalization(object):\n",
    "    def __init__(self, mean=0.5, std=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # label, input = data['label'], data['input']\n",
    "        #\n",
    "        # input = (input - self.mean) / self.std\n",
    "        # label = (label - self.mean) / self.std\n",
    "        #\n",
    "        # data = {'label': label, 'input': input}\n",
    "\n",
    "        # Updated at Apr 5 2020\n",
    "        for key, value in data.items():\n",
    "            data[key] = (value - self.mean) / self.std\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class RandomFlip(object):\n",
    "    def __call__(self, data):\n",
    "        # label, input = data['label'], data['input']\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            # label = np.fliplr(label)\n",
    "            # input = np.fliplr(input)\n",
    "\n",
    "            # Updated at Apr 5 2020\n",
    "            for key, value in data.items():\n",
    "                data[key] = np.flip(value, axis=0)\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            # label = np.flipud(label)\n",
    "            # input = np.flipud(input)\n",
    "\n",
    "            # Updated at Apr 5 2020\n",
    "            for key, value in data.items():\n",
    "                data[key] = np.flip(value, axis=1)\n",
    "\n",
    "        # data = {'label': label, 'input': input}\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "  def __init__(self, shape):\n",
    "      self.shape = shape\n",
    "\n",
    "  def __call__(self, data):\n",
    "    # input, label = data['input'], data['label']\n",
    "    # h, w = input.shape[:2]\n",
    "\n",
    "    h, w = data['label'].shape[:2]\n",
    "    new_h, new_w = self.shape\n",
    "\n",
    "    top = np.random.randint(0, h - new_h)\n",
    "    left = np.random.randint(0, w - new_w)\n",
    "\n",
    "    id_y = np.arange(top, top + new_h, 1)[:, np.newaxis]\n",
    "    id_x = np.arange(left, left + new_w, 1)\n",
    "\n",
    "    # input = input[id_y, id_x]\n",
    "    # label = label[id_y, id_x]\n",
    "    # data = {'label': label, 'input': input}\n",
    "\n",
    "    # Updated at Apr 5 2020\n",
    "    for key, value in data.items():\n",
    "        data[key] = value[id_y, id_x]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a640f603ca72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;31m# layer에 CBR2d class import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'layer'"
     ]
    }
   ],
   "source": [
    "from layer import * # layer에 CBR2d class import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a6016c073ab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;31m# layer에 CBR2d class import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'layer'"
     ]
    }
   ],
   "source": [
    "## 네트워크 구축\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,nch,nker,norm = 'bnorm',learning_type ='plain'):\n",
    "        super(UNet, self).__init__()\n",
    "        self.learning_type = learning_type\n",
    "\n",
    "        # Contracting path\n",
    "        self.enc1_1 = CBR2d(in_channels=nch, out_channels=1*nker, norm=norm)\n",
    "        self.enc1_2 = CBR2d(in_channels=1*nker, out_channels=1*nker,norm=norm)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc2_1 = CBR2d(in_channels=1*nker, out_channels=2*nker,norm=norm)\n",
    "        self.enc2_2 = CBR2d(in_channels=2*nker, out_channels=2*nker,norm=norm)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc3_1 = CBR2d(in_channels=2*nker, out_channels=4*nker,norm=norm)\n",
    "        self.enc3_2 = CBR2d(in_channels=4*nker, out_channels=4*nker,norm=norm)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc4_1 = CBR2d(in_channels=4*nker, out_channels=8*nker,norm=norm)\n",
    "        self.enc4_2 = CBR2d(in_channels=8*nker, out_channels=8*nker,norm=norm)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc5_1 = CBR2d(in_channels=8*nker, out_channels=16*nker,norm=norm)\n",
    "\n",
    "        # Expansive path\n",
    "        self.dec5_1 = CBR2d(in_channels=16*nker, out_channels=8*nker,norm=norm)\n",
    "\n",
    "        self.unpool4 = nn.ConvTranspose2d(in_channels=8*nker, out_channels=8*nker,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec4_2 = CBR2d(in_channels=2 * 8*nker, out_channels=8*nker,norm=norm)\n",
    "        self.dec4_1 = CBR2d(in_channels=8*nker, out_channels=4*nker,norm=norm)\n",
    "\n",
    "        self.unpool3 = nn.ConvTranspose2d(in_channels=4*nker, out_channels=4*nker,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec3_2 = CBR2d(in_channels=2* 4*nker, out_channels=4*nker,norm=norm)\n",
    "        self.dec3_1 = CBR2d(in_channels=4*nker, out_channels=2*nker,norm=norm)\n",
    "\n",
    "        self.unpool2 = nn.ConvTranspose2d(in_channels=2*nker, out_channels=2*nker,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec2_2 = CBR2d(in_channels=2 * 2*nker, out_channels=2*nker,norm=norm)\n",
    "        self.dec2_1 = CBR2d(in_channels=2*nker, out_channels=1*nker,norm=norm)\n",
    "\n",
    "        self.unpool1 = nn.ConvTranspose2d(in_channels=1*nker, out_channels=1*nker,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec1_2 = CBR2d(in_channels=2 * 1*nker, out_channels=1*nker,norm=norm)\n",
    "        self.dec1_1 = CBR2d(in_channels=1*nker, out_channels=1*nker,norm=norm)\n",
    "\n",
    "        self.fc = nn.Conv2d(in_channels=1*nker, out_channels=nch, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "\n",
    "        dec5_1 = self.dec5_1(enc5_1)\n",
    "\n",
    "        unpool4 = self.unpool4(dec5_1)\n",
    "        cat4 = torch.cat((unpool4, enc4_2), dim=1)\n",
    "        dec4_2 = self.dec4_2(cat4)\n",
    "        dec4_1 = self.dec4_1(dec4_2)\n",
    "\n",
    "        unpool3 = self.unpool3(dec4_1)\n",
    "        cat3 = torch.cat((unpool3, enc3_2), dim=1)\n",
    "        dec3_2 = self.dec3_2(cat3)\n",
    "        dec3_1 = self.dec3_1(dec3_2)\n",
    "\n",
    "        unpool2 = self.unpool2(dec3_1)\n",
    "        cat2 = torch.cat((unpool2, enc2_2), dim=1)\n",
    "        dec2_2 = self.dec2_2(cat2)\n",
    "        dec2_1 = self.dec2_1(dec2_2)\n",
    "\n",
    "        unpool1 = self.unpool1(dec2_1)\n",
    "        cat1 = torch.cat((unpool1, enc1_2), dim=1)\n",
    "        dec1_2 = self.dec1_2(cat1)\n",
    "        dec1_1 = self.dec1_1(dec1_2)\n",
    "\n",
    "        if self.learning_type == 'plain':\n",
    "            out = self.fc(dec1_1)\n",
    "        elif self.learning_type == 'residual':\n",
    "            out = self.fc(dec1_1) + x   # output과 네트워크 인풋을 더해 최종 아웃풋으로 낸다(residual learning)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
